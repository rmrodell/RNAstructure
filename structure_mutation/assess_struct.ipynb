{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a267c8",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb70b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Helper Functions\n",
    "import pandas as pd\n",
    "import RNA\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e1255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dotbracket_to_pairset(db_string: str) -> set:\n",
    "    \"\"\"Converts a dot-bracket string to a set of 1-indexed base pairs.\"\"\"\n",
    "    pairs = set()\n",
    "    stack = []\n",
    "    for i, char in enumerate(db_string):\n",
    "        # Use 1-based indexing for biological convention\n",
    "        pos = i + 1\n",
    "        if char == '(':\n",
    "            stack.append(pos)\n",
    "        elif char == ')':\n",
    "            if stack:\n",
    "                j = stack.pop()\n",
    "                # Store pair as (smaller_index, larger_index)\n",
    "                pairs.add((j, pos))\n",
    "    return pairs\n",
    "\n",
    "# def parse_target_region(region_string: str) -> list:\n",
    "#     \"\"\"Converts a region string like '50-52' or '50' to a list of integers.\"\"\"\n",
    "#     if not region_string or pd.isna(region_string):\n",
    "#         return []\n",
    "#     region_string = str(region_string)\n",
    "#     if '-' in region_string:\n",
    "#         start, end = map(int, region_string.split('-'))\n",
    "#         return list(range(start, end + 1))\n",
    "#     else:\n",
    "#         return [int(region_string)]\n",
    "\n",
    "def parse_target_region(region_string) -> list:\n",
    "    \"\"\"\n",
    "    Parses a complex region string like '50', '50-52', or '56-63, 69-81'\n",
    "    into a list of all integer positions.\n",
    "    \"\"\"\n",
    "    if pd.isna(region_string) or region_string == '':\n",
    "        return []\n",
    "    region_string = str(region_string).replace(' ', '')\n",
    "    all_positions = []\n",
    "    parts = region_string.split(',')\n",
    "    for part in parts:\n",
    "        try:\n",
    "            if '-' in part:\n",
    "                start, end = map(int, part.split('-'))\n",
    "                all_positions.extend(range(start, end + 1))\n",
    "            else:\n",
    "                all_positions.append(int(part))\n",
    "        except ValueError:\n",
    "            print(f\"Warning: Could not parse part of a region string: '{part}'\")\n",
    "            continue\n",
    "    return all_positions\n",
    "\n",
    "def set_to_str(s: set) -> str:\n",
    "    \"\"\"Converts a set of tuples to a sorted, human-readable string for CSV output.\"\"\"\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    return \"; \".join(map(str, sorted(list(s))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80d94707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'run_analysis_engine' function is defined.\n"
     ]
    }
   ],
   "source": [
    "# The Core Analysis Engine (Reworked with Correct Order of Operations)\n",
    "\n",
    "def run_analysis_engine(\n",
    "    mutant_ids: pd.Series,\n",
    "    parent_seqs: pd.Series,\n",
    "    mutant_seqs: pd.Series,\n",
    "    parent_dbs: pd.Series,\n",
    "    mutant_dbs: pd.Series,\n",
    "    goal_types: pd.Series,\n",
    "    target_regions_1: pd.Series\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Analyzes structural differences between parent and mutant RNAs.\n",
    "\n",
    "    This robust function takes pandas Series of sequence/structure data, calculates\n",
    "    distance metrics, and performs goal-specific analysis via substring matching.\n",
    "\n",
    "    Args:\n",
    "        mutant_ids (pd.Series): Unique string identifiers for each mutant.\n",
    "        parent_seqs (pd.Series): Parent RNA sequences.\n",
    "        mutant_seqs (pd.Series): Mutant RNA sequences.\n",
    "        parent_dbs (pd.Series): Parent dot-bracket structure strings.\n",
    "        mutant_dbs (pd.Series): Mutant dot-bracket structure strings.\n",
    "        goal_types (pd.Series): Goal descriptions for substring matching. Keywords:\n",
    "            \"break_pair\", \"disruption\", \"extend_stem\", \"seed_hairpin\",\n",
    "            \"compensatory\", \"stabilizing\", \"destabilizing\".\n",
    "        target_regions_1 (pd.Series): Primary target region, e.g., '50' or '50-52'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with analysis results, one row per mutant.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    num_entries = len(mutant_ids)\n",
    "    print(f\"Starting analysis of {num_entries} entries...\")\n",
    "\n",
    "    iterator = zip(\n",
    "        mutant_ids, parent_seqs, mutant_seqs, parent_dbs, mutant_dbs, \n",
    "        goal_types, target_regions_1\n",
    "    )\n",
    "\n",
    "    for i, (mutant_id, p_seq, m_seq, p_db, m_db, goal, tr1_str) in enumerate(iterator):\n",
    "        \n",
    "        result_row = {'mutant_id': mutant_id, 'goal_type': goal, 'parent_seq': p_seq, 'mutant_seq': m_seq}\n",
    "\n",
    "        target_region_1 = parse_target_region(tr1_str)\n",
    "        # --- Core Metric Calculations ---\n",
    "        \n",
    "        parent_tree_repr = RNA.db_to_tree_string(p_db, RNA.STRUCTURE_TREE_SHAPIRO_WEIGHT)\n",
    "        mutant_tree_repr = RNA.db_to_tree_string(m_db, RNA.STRUCTURE_TREE_SHAPIRO_WEIGHT)\n",
    "        result_row['parent_tree_repr'] = parent_tree_repr\n",
    "        result_row['mutant_tree_repr'] = mutant_tree_repr\n",
    "        \n",
    "        # Calculate Tree Edit Distance \n",
    "        tree_parent, tree_mutant = None, None\n",
    "        try:\n",
    "            # Create computational Tree objects \n",
    "            tree_parent = RNA.make_tree(parent_tree_repr)\n",
    "            tree_mutant = RNA.make_tree(mutant_tree_repr)\n",
    "            \n",
    "            # Calculate distance using the valid tree objects.\n",
    "            result_row['TreeEditDistance'] = RNA.tree_edit_distance(tree_parent, tree_mutant)\n",
    "        finally:\n",
    "            # Free the allocated memory.\n",
    "            if tree_parent: RNA.free_tree(tree_parent)\n",
    "            if tree_mutant: RNA.free_tree(tree_mutant)\n",
    "\n",
    "        # Calculate Base Pair distance\n",
    "        result_row['Full_BP_Distance'] = RNA.bp_distance(p_db, m_db)\n",
    "        \n",
    "        # --- Sequence & Pair Analysis ---\n",
    "        mutations = [f\"{p_seq[i]}{i+1}{m_seq[i]}\" for i in range(len(p_seq)) if p_seq[i] != m_seq[i]]\n",
    "        result_row['Sequence_Changes'] = \"; \".join(mutations)\n",
    "        \n",
    "        p_parent_set = dotbracket_to_pairset(p_db)\n",
    "        p_mutant_set = dotbracket_to_pairset(m_db)\n",
    "        sym_diff = p_parent_set.symmetric_difference(p_mutant_set)\n",
    "        \n",
    "        changed_pairs_annotated = []\n",
    "        for pair_i, pair_j in sorted(list(sym_diff)):\n",
    "            if (pair_i, pair_j) in p_parent_set:\n",
    "                pair_str = f\"{p_seq[pair_i-1]}{pair_i}-{p_seq[pair_j-1]}{pair_j}\"\n",
    "                changed_pairs_annotated.append(f\"Broke {pair_str}\")\n",
    "            elif (pair_i, pair_j) in p_mutant_set:\n",
    "                pair_str = f\"{m_seq[pair_i-1]}{pair_i}-{m_seq[pair_j-1]}{pair_j}\"\n",
    "                changed_pairs_annotated.append(f\"Formed {pair_str}\")\n",
    "        result_row['Annotated_Pair_Changes'] = \"; \".join(changed_pairs_annotated)\n",
    "        \n",
    "        # --- Goal-Specific Logic ---\n",
    "        on_target_score, off_target_score, intended_changes, logic_type = \"N/A\", \"N/A\", set(), \"unknown\"\n",
    "        \n",
    "        if \"break_pair\" in goal:\n",
    "            logic_type = \"break_pair\"\n",
    "            on_target_score = sum(1 for pos in target_region_1 if m_db[pos - 1] == '.')\n",
    "            intended_changes = {p for p in p_parent_set if p[0] in target_region_1 or p[1] in target_region_1}\n",
    "            off_target_pairs = sym_diff - intended_changes\n",
    "            off_target_score = len(off_target_pairs)\n",
    "\n",
    "        elif \"extend_stem\" in goal or \"seed_hairpin\" in goal:\n",
    "            logic_type = \"make_pair\"\n",
    "            on_target_score = sum(1 for pos in target_region_1 if m_db[pos - 1] in '()')\n",
    "            intended_changes = {p for p in p_mutant_set if p[0] in target_region_1 or p[1] in target_region_1}\n",
    "            off_target_pairs = sym_diff - intended_changes\n",
    "            off_target_score = len(off_target_pairs)\n",
    "\n",
    "        elif \"downstream_disruption\" in goal or \"upstream_disruption\" in goal or \"total_disruption\" in goal:\n",
    "            logic_type = \"disruption\"\n",
    "            paired_in_target = sum(1 for pos in target_region_1 if m_db[pos - 1] != '.')\n",
    "            on_target_score = paired_in_target\n",
    "            intended_changes = {p for p in p_parent_set if p[0] in target_region_1 or p[1] in target_region_1}\n",
    "            off_target_pairs = sym_diff - intended_changes\n",
    "            off_target_score = len(off_target_pairs)\n",
    "\n",
    "        elif \"downstream_compensation\" in goal or \"upstream_compensation\" in goal or \"total_compensation\" in goal:\n",
    "            logic_type = \"compensatory\"\n",
    "            # on_target_score = result_row['Full_BP_Distance']\n",
    "            # off_target_score = len(sym_diff)\n",
    "\n",
    "            parent_partner_map = {i: j for i, j in p_parent_set}\n",
    "            parent_partner_map.update({j: i for i, j in p_parent_set})\n",
    "            mutant_partner_map = {i: j for i, j in p_mutant_set}\n",
    "            mutant_partner_map.update({j: i for i, j in p_mutant_set})\n",
    "\n",
    "            restored_pair_count = 0\n",
    "            for pos in target_region_1:\n",
    "                original_partner = parent_partner_map.get(pos)\n",
    "                mutant_partner = mutant_partner_map.get(pos)\n",
    "                if original_partner is not None:\n",
    "                    if mutant_partner == original_partner:\n",
    "                        restored_pair_count += 1\n",
    "                else:\n",
    "                    if mutant_partner is None:\n",
    "                        restored_pair_count += 1\n",
    "\n",
    "            on_target_score = len(target_region_1) - restored_pair_count\n",
    "            off_target_score = result_row['Full_BP_Distance']\n",
    "\n",
    "        elif \"stabilizing\" in goal or \"destabilizing\" in goal:\n",
    "            logic_type = \"stability\"\n",
    "            on_target_score = \"N/A\"\n",
    "            off_target_score = result_row['Full_BP_Distance']\n",
    "\n",
    "        else:\n",
    "            print(f\"Warning: Goal '{goal}' for mutant '{mutant_id}' did not match any known keywords.\")\n",
    "\n",
    "        result_row['Logic_Type_Applied'] = logic_type\n",
    "        result_row['OnTargetScore'] = on_target_score\n",
    "        result_row['OffTargetScore'] = off_target_score\n",
    "        result_row['IntendedChange_Pairs(positions)'] = set_to_str(intended_changes)\n",
    "        \n",
    "        results.append(result_row)\n",
    "        \n",
    "    # --- Finalize DataFrame ---\n",
    "    output_df = pd.DataFrame(results)\n",
    "    column_order = [\n",
    "        'mutant_id', 'goal_type', 'Logic_Type_Applied', 'Sequence_Changes',\n",
    "        'TreeEditDistance', 'OnTargetScore', 'OffTargetScore', 'Full_BP_Distance', \n",
    "        'parent_tree_repr', 'mutant_tree_repr', 'Annotated_Pair_Changes', \n",
    "        'IntendedChange_Pairs(positions)', \"parent_seq\", \"mutant_seq\"\n",
    "    ]\n",
    "    # Use reindex to safely order columns, filling missing ones with NaN\n",
    "    output_df = output_df.reindex(columns=column_order)\n",
    "    \n",
    "    print(\"Analysis function finished.\")\n",
    "    return output_df\n",
    "\n",
    "print(\"'run_analysis_engine' function is defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56dffb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUS7 data loaded and merged successfully. Number of sequences: 296\n",
      "UNUAR data loaded and merged successfully. Number of sequences: 337\n"
     ]
    }
   ],
   "source": [
    "# Define PUS7 Union\n",
    "\n",
    "# Load the two CSV files into pandas DataFrames\n",
    "incell_pus7_path = \"C:/Users/rmrex/OneDrive - Stanford/Martinez Lab/R/Pool1_FINALANALYSIS/delpos/site_sum/PUS7dep_sites_fulllist.csv\"\n",
    "invitro_pus7_path = \"C:/Users/rmrex/OneDrive - Stanford/Martinez Lab/R/ivBID/202506/ivPUS7_sig_sites.csv\"\n",
    "\n",
    "incell_PUS7_df = pd.read_csv(incell_pus7_path)\n",
    "invitro_PUS7_df = pd.read_csv(invitro_pus7_path)\n",
    "\n",
    "PUS7_union_df = pd.merge(incell_PUS7_df, invitro_PUS7_df, on=\"chr\", how=\"outer\")\n",
    "\n",
    "print(f\"PUS7 data loaded and merged successfully. Number of sequences: {len(PUS7_union_df)}\")\n",
    "\n",
    "\n",
    "pool_path = \"C:/Users/rmrex/OneDrive - Stanford/Martinez Lab/R/Pool1_Sequences/pool1_pos.xlsx\"\n",
    "pool_df = pd.read_excel(pool_path)\n",
    "\n",
    "regex_pattern = r\"^T[ACGT]TA[AG]$\"\n",
    "unuar_mask = pool_df['psipos_5mer'].str.contains(regex_pattern, regex=True, na=False)\n",
    "unuar_df = pool_df.loc[unuar_mask]\n",
    "\n",
    "print(f\"UNUAR data loaded and merged successfully. Number of sequences: {len(unuar_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee7e941",
   "metadata": {},
   "source": [
    "# Execution  \n",
    "\n",
    "## Psi Pairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "374a3989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded successfully.\n",
      "Starting analysis of 565 entries...\n",
      "Analysis function finished.\n",
      "Creating DataFrame for logic type: 'break_pair' with 289 rows.\n",
      "Creating DataFrame for logic type: 'make_pair' with 276 rows.\n",
      "Number of break pair: 289\n",
      "Number of make pair: 276\n",
      "Number of good break pair: 7\n",
      "\n",
      "Analysis complete. Results saved.\n"
     ]
    }
   ],
   "source": [
    "unmod_access_psi=\"C:/Users/rmrex/OneDrive - Stanford/Martinez Lab/R/Pool2_Mutagenesis/Abridged/psi_pairing/pairing_status_flip_analysis.csv\"\n",
    "\n",
    "unmod_access_psi_df = pd.read_csv(unmod_access_psi)\n",
    "\n",
    "column_mapping = {\n",
    "    'mutant_ids': unmod_access_psi_df['name'],\n",
    "    'parent_seqs': unmod_access_psi_df['original_seq'],\n",
    "    'mutant_seqs': unmod_access_psi_df['mutated_seq'],\n",
    "    'parent_dbs': unmod_access_psi_df['original_dot_bracket'],\n",
    "    'mutant_dbs': unmod_access_psi_df['dot_bracket_mut'],\n",
    "    'goal_types': unmod_access_psi_df['strategy'],\n",
    "    'target_regions_1': unmod_access_psi_df['target_pos']\n",
    "}\n",
    "\n",
    "print(\"DataFrame loaded successfully.\")\n",
    "\n",
    "results_df = run_analysis_engine(**column_mapping)\n",
    "\n",
    "dfs_by_logic = {}\n",
    "\n",
    "for name, group in results_df.groupby('Logic_Type_Applied'):\n",
    "    print(f\"Creating DataFrame for logic type: '{name}' with {len(group)} rows.\")\n",
    "    dfs_by_logic[name] = group\n",
    "\n",
    "break_pair_df = dfs_by_logic.get('break_pair')\n",
    "make_pair_df = dfs_by_logic.get('make_pair')\n",
    "\n",
    "print(f\"Number of break pair: {len(break_pair_df)}\")\n",
    "print(f\"Number of make pair: {len(make_pair_df)}\")\n",
    "\n",
    "break_pair_ted_threshold = break_pair_df['TreeEditDistance'].quantile(0.03)\n",
    "make_pair_ted_threshold = make_pair_df['TreeEditDistance'].quantile(0.1)\n",
    "\n",
    "break_pair_off_threshold = break_pair_df['TreeEditDistance'].quantile(0.03)\n",
    "make_pair_off_threshold = make_pair_df['TreeEditDistance'].quantile(0.1)\n",
    "\n",
    "good_break_pair_df = break_pair_df.loc[(break_pair_df['TreeEditDistance'] <= break_pair_ted_threshold) \n",
    "                                       & (break_pair_df['OnTargetScore'] == 1) \n",
    "                                       & (break_pair_df['OffTargetScore'] <= break_pair_off_threshold)]\n",
    "good_make_pair_df = make_pair_df.loc[(make_pair_df['TreeEditDistance'] <= make_pair_ted_threshold) \n",
    "                                     & (make_pair_df['OnTargetScore'] == 1)\n",
    "                                     & (make_pair_df['OffTargetScore'] <= make_pair_off_threshold)]\n",
    "\n",
    "print(f\"Number of good break pair: {len(good_break_pair_df)}\")\n",
    "\n",
    "good_break_pair_df.to_csv(\"unmod_good_breakpair_psi.csv\", index=False)\n",
    "\n",
    "print(f\"\\nAnalysis complete. Results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b933aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded successfully.\n",
      "Starting analysis of 634 entries...\n",
      "Analysis function finished.\n",
      "Creating DataFrame for logic type: 'break_pair' with 234 rows.\n",
      "Creating DataFrame for logic type: 'make_pair' with 400 rows.\n",
      "Number of break pair: 112\n",
      "Number of make pair: 150\n",
      "Number of good break pair: 31\n",
      "Number of good make pair: 39\n",
      "\n",
      "Analysis complete. Results saved.\n"
     ]
    }
   ],
   "source": [
    "pool_access_psi=\"C:/Users/rmrex/OneDrive - Stanford/Martinez Lab/R/Pool2_Mutagenesis/Abridged/psi_pairing/pairing_status_flip_analysis_pool1.csv\"\n",
    "\n",
    "pool_access_psi_df = pd.read_csv(pool_access_psi)\n",
    "\n",
    "column_mapping = {\n",
    "    'mutant_ids': pool_access_psi_df['name'],\n",
    "    'parent_seqs': pool_access_psi_df['original_seq'],\n",
    "    'mutant_seqs': pool_access_psi_df['mutated_seq'],\n",
    "    'parent_dbs': pool_access_psi_df['original_dot_bracket'],\n",
    "    'mutant_dbs': pool_access_psi_df['dot_bracket_mut'],\n",
    "    'goal_types': pool_access_psi_df['strategy'],\n",
    "    'target_regions_1': pool_access_psi_df['target_pos']\n",
    "}\n",
    "\n",
    "print(\"DataFrame loaded successfully.\")\n",
    "\n",
    "results_df = run_analysis_engine(**column_mapping)\n",
    "\n",
    "dfs_by_logic = {}\n",
    "\n",
    "for name, group in results_df.groupby('Logic_Type_Applied'):\n",
    "    print(f\"Creating DataFrame for logic type: '{name}' with {len(group)} rows.\")\n",
    "    dfs_by_logic[name] = group\n",
    "\n",
    "pool_break_pair_df = dfs_by_logic.get('break_pair')\n",
    "pool_make_pair_df = dfs_by_logic.get('make_pair')\n",
    "\n",
    "# The concise, single-line solution\n",
    "poolPUS7_make_pair_df = pool_make_pair_df[pool_make_pair_df['mutant_id'].isin(PUS7_union_df['chr'])]\n",
    "poolPUS7_break_pair_df = pool_break_pair_df[pool_break_pair_df['mutant_id'].isin(unuar_df['chr'])]\n",
    "\n",
    "print(f\"Number of break pair: {len(poolPUS7_break_pair_df)}\")\n",
    "print(f\"Number of make pair: {len(poolPUS7_make_pair_df)}\")\n",
    "\n",
    "pool_break_pair_ted_threshold = poolPUS7_break_pair_df['TreeEditDistance'].quantile(0.5)\n",
    "pool_make_pair_ted_threshold = poolPUS7_make_pair_df['TreeEditDistance'].quantile(0.5)\n",
    "\n",
    "pool_break_pair_off_threshold = poolPUS7_break_pair_df['OffTargetScore'].quantile(0.5)\n",
    "pool_make_pair_off_threshold = poolPUS7_make_pair_df['OffTargetScore'].quantile(0.5)\n",
    "\n",
    "pool_good_break_pair_df = poolPUS7_break_pair_df.loc[(poolPUS7_break_pair_df['OnTargetScore'] == 1)\n",
    "                                        & (poolPUS7_break_pair_df['TreeEditDistance'] <= pool_break_pair_ted_threshold) \n",
    "                                        & (poolPUS7_break_pair_df['OffTargetScore'] <= pool_break_pair_off_threshold)\n",
    "                                        ]\n",
    "pool_good_make_pair_df = poolPUS7_make_pair_df.loc[(poolPUS7_make_pair_df['OnTargetScore'] == 1)\n",
    "                                        &  (poolPUS7_make_pair_df['TreeEditDistance'] <= pool_make_pair_ted_threshold) \n",
    "                                        & (poolPUS7_make_pair_df['OffTargetScore'] <= pool_make_pair_off_threshold)\n",
    "                                        ]\n",
    "\n",
    "print(f\"Number of good break pair: {len(pool_good_break_pair_df)}\")\n",
    "print(f\"Number of good make pair: {len(pool_good_make_pair_df)}\")\n",
    "\n",
    "pool_good_break_pair_df.to_csv(\"pool_good_breakpair_psi.csv\", index=False)\n",
    "pool_good_make_pair_df.to_csv(\"pool_good_makepair_psi.csv\", index=False)\n",
    "print(f\"\\nAnalysis complete. Results saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eb6ea4",
   "metadata": {},
   "source": [
    "## Psi +1 Pairing Accessibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2376fd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded successfully.\n",
      "Starting analysis of 575 entries...\n",
      "Analysis function finished.\n",
      "Creating DataFrame for logic type: 'break_pair' with 343 rows.\n",
      "Creating DataFrame for logic type: 'make_pair' with 232 rows.\n",
      "Number of break pair: 343\n",
      "Number of make pair: 232\n",
      "Number of good break pair: 4\n",
      "\n",
      "Analysis complete. Results saved.\n"
     ]
    }
   ],
   "source": [
    "unmod_access_psi=\"C:/Users/rmrex/OneDrive - Stanford/Martinez Lab/R/Pool2_Mutagenesis/Abridged/psi_pairing/pairing_status_flip_analysis01.csv\"\n",
    "\n",
    "unmod_access_psi_df = pd.read_csv(unmod_access_psi)\n",
    "\n",
    "column_mapping = {\n",
    "    'mutant_ids': unmod_access_psi_df['name'],\n",
    "    'parent_seqs': unmod_access_psi_df['original_seq'],\n",
    "    'mutant_seqs': unmod_access_psi_df['mutated_seq'],\n",
    "    'parent_dbs': unmod_access_psi_df['original_dot_bracket'],\n",
    "    'mutant_dbs': unmod_access_psi_df['dot_bracket_mut'],\n",
    "    'goal_types': unmod_access_psi_df['strategy'],\n",
    "    'target_regions_1': unmod_access_psi_df['target_pos']\n",
    "}\n",
    "\n",
    "print(\"DataFrame loaded successfully.\")\n",
    "\n",
    "results_df = run_analysis_engine(**column_mapping)\n",
    "\n",
    "dfs_by_logic = {}\n",
    "\n",
    "for name, group in results_df.groupby('Logic_Type_Applied'):\n",
    "    print(f\"Creating DataFrame for logic type: '{name}' with {len(group)} rows.\")\n",
    "    dfs_by_logic[name] = group\n",
    "\n",
    "break_pair_df = dfs_by_logic.get('break_pair')\n",
    "make_pair_df = dfs_by_logic.get('make_pair')\n",
    "\n",
    "print(f\"Number of break pair: {len(break_pair_df)}\")\n",
    "print(f\"Number of make pair: {len(make_pair_df)}\")\n",
    "\n",
    "break_pair_ted_threshold = break_pair_df['TreeEditDistance'].quantile(0.03)\n",
    "make_pair_ted_threshold = make_pair_df['TreeEditDistance'].quantile(0.1)\n",
    "\n",
    "break_pair_off_threshold = break_pair_df['TreeEditDistance'].quantile(0.03)\n",
    "make_pair_off_threshold = make_pair_df['TreeEditDistance'].quantile(0.1)\n",
    "\n",
    "good_break_pair_df = break_pair_df.loc[(break_pair_df['TreeEditDistance'] <= break_pair_ted_threshold) \n",
    "                                       & (break_pair_df['OnTargetScore'] == 2) \n",
    "                                       & (break_pair_df['OffTargetScore'] <= break_pair_off_threshold)]\n",
    "good_make_pair_df = make_pair_df.loc[(make_pair_df['TreeEditDistance'] <= make_pair_ted_threshold) \n",
    "                                     & (make_pair_df['OnTargetScore'] == 2)\n",
    "                                     & (make_pair_df['OffTargetScore'] <= make_pair_off_threshold)]\n",
    "\n",
    "print(f\"Number of good break pair: {len(good_break_pair_df)}\")\n",
    "\n",
    "good_break_pair_df.to_csv(\"unmod_good_breakpair_psi01.csv\", index=False)\n",
    "print(f\"\\nAnalysis complete. Results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29cb98a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded successfully.\n",
      "Starting analysis of 644 entries...\n",
      "Analysis function finished.\n",
      "Creating DataFrame for logic type: 'break_pair' with 306 rows.\n",
      "Creating DataFrame for logic type: 'make_pair' with 338 rows.\n",
      "Number of break pair: 148\n",
      "Number of make pair: 126\n",
      "Number of good break pair: 25\n",
      "Number of good make pair: 35\n",
      "\n",
      "Analysis complete. Results saved.\n"
     ]
    }
   ],
   "source": [
    "pool_access_psi=\"C:/Users/rmrex/OneDrive - Stanford/Martinez Lab/R/Pool2_Mutagenesis/Abridged/psi_pairing/pairing_status_flip_analysis01_pool1.csv\"\n",
    "\n",
    "pool_access_psi_df = pd.read_csv(pool_access_psi)\n",
    "\n",
    "column_mapping = {\n",
    "    'mutant_ids': pool_access_psi_df['name'],\n",
    "    'parent_seqs': pool_access_psi_df['original_seq'],\n",
    "    'mutant_seqs': pool_access_psi_df['mutated_seq'],\n",
    "    'parent_dbs': pool_access_psi_df['original_dot_bracket'],\n",
    "    'mutant_dbs': pool_access_psi_df['dot_bracket_mut'],\n",
    "    'goal_types': pool_access_psi_df['strategy'],\n",
    "    'target_regions_1': pool_access_psi_df['target_pos']\n",
    "}\n",
    "\n",
    "print(\"DataFrame loaded successfully.\")\n",
    "\n",
    "results_df = run_analysis_engine(**column_mapping)\n",
    "\n",
    "dfs_by_logic = {}\n",
    "\n",
    "for name, group in results_df.groupby('Logic_Type_Applied'):\n",
    "    print(f\"Creating DataFrame for logic type: '{name}' with {len(group)} rows.\")\n",
    "    dfs_by_logic[name] = group\n",
    "\n",
    "pool_break_pair_df = dfs_by_logic.get('break_pair')\n",
    "pool_make_pair_df = dfs_by_logic.get('make_pair')\n",
    "\n",
    "# The concise, single-line solution\n",
    "poolPUS7_make_pair_df = pool_make_pair_df[pool_make_pair_df['mutant_id'].isin(PUS7_union_df['chr'])]\n",
    "poolPUS7_break_pair_df = pool_break_pair_df[pool_break_pair_df['mutant_id'].isin(unuar_df['chr'])]\n",
    "\n",
    "print(f\"Number of break pair: {len(poolPUS7_break_pair_df)}\")\n",
    "print(f\"Number of make pair: {len(poolPUS7_make_pair_df)}\")\n",
    "\n",
    "pool_break_pair_ted_threshold = poolPUS7_break_pair_df['TreeEditDistance'].quantile(0.5)\n",
    "pool_make_pair_ted_threshold = poolPUS7_make_pair_df['TreeEditDistance'].quantile(0.5)\n",
    "\n",
    "pool_break_pair_off_threshold = poolPUS7_break_pair_df['OffTargetScore'].quantile(0.5)\n",
    "pool_make_pair_off_threshold = poolPUS7_make_pair_df['OffTargetScore'].quantile(0.5)\n",
    "\n",
    "pool_good_break_pair_df = poolPUS7_break_pair_df.loc[(poolPUS7_break_pair_df['OnTargetScore'] == 2)\n",
    "                                        & (poolPUS7_break_pair_df['TreeEditDistance'] <= pool_break_pair_ted_threshold) \n",
    "                                        & (poolPUS7_break_pair_df['OffTargetScore'] <= pool_break_pair_off_threshold)\n",
    "                                        ]\n",
    "pool_good_make_pair_df = poolPUS7_make_pair_df.loc[(poolPUS7_make_pair_df['OnTargetScore'] == 2)\n",
    "                                        &  (poolPUS7_make_pair_df['TreeEditDistance'] <= pool_make_pair_ted_threshold) \n",
    "                                        & (poolPUS7_make_pair_df['OffTargetScore'] <= pool_make_pair_off_threshold)\n",
    "                                        ]\n",
    "\n",
    "print(f\"Number of good break pair: {len(pool_good_break_pair_df)}\")\n",
    "print(f\"Number of good make pair: {len(pool_good_make_pair_df)}\")\n",
    "\n",
    "pool_good_break_pair_df.to_csv(\"pool_good_breakpair_psi01.csv\", index=False)\n",
    "pool_good_make_pair_df.to_csv(\"pool_good_makepair_psi01.csv\", index=False)\n",
    "print(f\"\\nAnalysis complete. Results saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153d0824",
   "metadata": {},
   "source": [
    "## Psipos 5mer Pairing Accessibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67030ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded successfully.\n",
      "Starting analysis of 574 entries...\n",
      "Analysis function finished.\n",
      "Creating DataFrame for logic type: 'break_pair' with 487 rows.\n",
      "Creating DataFrame for logic type: 'make_pair' with 87 rows.\n",
      "Number of break pair: 487\n",
      "Number of make pair: 87\n",
      "Number of good break pair: 12\n",
      "\n",
      "Analysis complete. Results saved.\n"
     ]
    }
   ],
   "source": [
    "unmod_access_psi=\"C:/Users/rmrex/OneDrive - Stanford/Martinez Lab/R/Pool2_Mutagenesis/Abridged/psi_pairing/pairing_status_flip_analysis5mer.csv\"\n",
    "\n",
    "unmod_access_psi_df = pd.read_csv(unmod_access_psi)\n",
    "\n",
    "column_mapping = {\n",
    "    'mutant_ids': unmod_access_psi_df['name'],\n",
    "    'parent_seqs': unmod_access_psi_df['original_seq'],\n",
    "    'mutant_seqs': unmod_access_psi_df['mutated_seq'],\n",
    "    'parent_dbs': unmod_access_psi_df['original_dot_bracket'],\n",
    "    'mutant_dbs': unmod_access_psi_df['dot_bracket_mut'],\n",
    "    'goal_types': unmod_access_psi_df['strategy'],\n",
    "    'target_regions_1': unmod_access_psi_df['target_pos_range']\n",
    "}\n",
    "\n",
    "print(\"DataFrame loaded successfully.\")\n",
    "\n",
    "results_df = run_analysis_engine(**column_mapping)\n",
    "\n",
    "dfs_by_logic = {}\n",
    "\n",
    "for name, group in results_df.groupby('Logic_Type_Applied'):\n",
    "    print(f\"Creating DataFrame for logic type: '{name}' with {len(group)} rows.\")\n",
    "    dfs_by_logic[name] = group\n",
    "\n",
    "break_pair_df = dfs_by_logic.get('break_pair')\n",
    "make_pair_df = dfs_by_logic.get('make_pair')\n",
    "\n",
    "print(f\"Number of break pair: {len(break_pair_df)}\")\n",
    "print(f\"Number of make pair: {len(make_pair_df)}\")\n",
    "\n",
    "break_pair_ted_threshold = break_pair_df['TreeEditDistance'].quantile(0.03)\n",
    "make_pair_ted_threshold = make_pair_df['TreeEditDistance'].quantile(0.1)\n",
    "\n",
    "break_pair_off_threshold = break_pair_df['TreeEditDistance'].quantile(0.03)\n",
    "make_pair_off_threshold = make_pair_df['TreeEditDistance'].quantile(0.1)\n",
    "\n",
    "good_break_pair_df = break_pair_df.loc[(break_pair_df['OnTargetScore'] == 5)\n",
    "                                       & (break_pair_df['TreeEditDistance'] <= break_pair_ted_threshold) \n",
    "                                       & (break_pair_df['OffTargetScore'] <= break_pair_off_threshold)\n",
    "                                       ]\n",
    "good_make_pair_df = make_pair_df.loc[(make_pair_df['OnTargetScore'] == 5)\n",
    "                                     & (make_pair_df['TreeEditDistance'] <= make_pair_ted_threshold) \n",
    "                                     & (make_pair_df['OffTargetScore'] <= make_pair_off_threshold)\n",
    "                                     ]\n",
    "\n",
    "print(f\"Number of good break pair: {len(good_break_pair_df)}\")\n",
    "\n",
    "good_break_pair_df.to_csv(\"unmod_good_breakpair_5mer.csv\", index=False)\n",
    "print(f\"\\nAnalysis complete. Results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc41edef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded successfully.\n",
      "Starting analysis of 628 entries...\n",
      "Analysis function finished.\n",
      "Creating DataFrame for logic type: 'break_pair' with 495 rows.\n",
      "Creating DataFrame for logic type: 'make_pair' with 133 rows.\n",
      "Number of break pair: 247\n",
      "Number of make pair: 50\n",
      "Number of good break pair: 28\n",
      "Number of good make pair: 7\n",
      "\n",
      "Analysis complete. Results saved.\n"
     ]
    }
   ],
   "source": [
    "pool_access_psi=\"C:/Users/rmrex/OneDrive - Stanford/Martinez Lab/R/Pool2_Mutagenesis/Abridged/psi_pairing/pairing_status_flip_analysis5mer_pool1.csv\"\n",
    "\n",
    "pool_access_psi_df = pd.read_csv(pool_access_psi)\n",
    "\n",
    "column_mapping = {\n",
    "    'mutant_ids': pool_access_psi_df['name'],\n",
    "    'parent_seqs': pool_access_psi_df['original_seq'],\n",
    "    'mutant_seqs': pool_access_psi_df['mutated_seq'],\n",
    "    'parent_dbs': pool_access_psi_df['original_dot_bracket'],\n",
    "    'mutant_dbs': pool_access_psi_df['dot_bracket_mut'],\n",
    "    'goal_types': pool_access_psi_df['strategy'],\n",
    "    'target_regions_1': pool_access_psi_df['target_pos_range']\n",
    "}\n",
    "\n",
    "print(\"DataFrame loaded successfully.\")\n",
    "\n",
    "results_df = run_analysis_engine(**column_mapping)\n",
    "\n",
    "dfs_by_logic = {}\n",
    "\n",
    "for name, group in results_df.groupby('Logic_Type_Applied'):\n",
    "    print(f\"Creating DataFrame for logic type: '{name}' with {len(group)} rows.\")\n",
    "    dfs_by_logic[name] = group\n",
    "\n",
    "pool_break_pair_df = dfs_by_logic.get('break_pair')\n",
    "pool_make_pair_df = dfs_by_logic.get('make_pair')\n",
    "\n",
    "# The concise, single-line solution\n",
    "poolPUS7_make_pair_df = pool_make_pair_df[pool_make_pair_df['mutant_id'].isin(PUS7_union_df['chr'])]\n",
    "poolPUS7_break_pair_df = pool_break_pair_df[pool_break_pair_df['mutant_id'].isin(unuar_df['chr'])]\n",
    "\n",
    "print(f\"Number of break pair: {len(poolPUS7_break_pair_df)}\")\n",
    "print(f\"Number of make pair: {len(poolPUS7_make_pair_df)}\")\n",
    "\n",
    "pool_break_pair_ted_threshold = poolPUS7_break_pair_df['TreeEditDistance'].quantile(0.5)\n",
    "pool_make_pair_ted_threshold = poolPUS7_make_pair_df['TreeEditDistance'].quantile(0.5)\n",
    "\n",
    "pool_break_pair_off_threshold = poolPUS7_break_pair_df['OffTargetScore'].quantile(0.5)\n",
    "pool_make_pair_off_threshold = poolPUS7_make_pair_df['OffTargetScore'].quantile(0.5)\n",
    "\n",
    "pool_good_break_pair_df = poolPUS7_break_pair_df.loc[(poolPUS7_break_pair_df['OnTargetScore'] == 5)\n",
    "                                        & (poolPUS7_break_pair_df['TreeEditDistance'] <= pool_break_pair_ted_threshold) \n",
    "                                        & (poolPUS7_break_pair_df['OffTargetScore'] <= pool_break_pair_off_threshold)\n",
    "                                        ]\n",
    "pool_good_make_pair_df = poolPUS7_make_pair_df.loc[(poolPUS7_make_pair_df['OnTargetScore'] == 5)\n",
    "                                        &  (poolPUS7_make_pair_df['TreeEditDistance'] <= pool_make_pair_ted_threshold) \n",
    "                                        & (poolPUS7_make_pair_df['OffTargetScore'] <= pool_make_pair_off_threshold)\n",
    "                                        ]\n",
    "\n",
    "print(f\"Number of good break pair: {len(pool_good_break_pair_df)}\")\n",
    "print(f\"Number of good make pair: {len(pool_good_make_pair_df)}\")\n",
    "\n",
    "pool_good_break_pair_df.to_csv(\"pool_good_breakpair_5mer.csv\", index=False)\n",
    "pool_good_make_pair_df.to_csv(\"pool_good_makepair_5mer.csv\", index=False)\n",
    "print(f\"\\nAnalysis complete. Results saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039ea7e6",
   "metadata": {},
   "source": [
    "## Unpaired2 Accessibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f8cc33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded successfully.\n",
      "Starting analysis of 545 entries...\n",
      "Analysis function finished.\n",
      "Creating DataFrame for logic type: 'break_pair' with 417 rows.\n",
      "Creating DataFrame for logic type: 'make_pair' with 128 rows.\n",
      "Number of break pair: 417\n",
      "Number of make pair: 128\n",
      "Number of good break pair: 12\n",
      "\n",
      "Analysis complete. Results saved.\n"
     ]
    }
   ],
   "source": [
    "unmod_access_psi=\"C:/Users/rmrex/OneDrive - Stanford/Martinez Lab/R/Pool2_Mutagenesis/Abridged/unpaired2_pairing/pairing_status_flip_analysis.csv\"\n",
    "\n",
    "unmod_access_psi_df = pd.read_csv(unmod_access_psi)\n",
    "\n",
    "column_mapping = {\n",
    "    'mutant_ids': unmod_access_psi_df['name'],\n",
    "    'parent_seqs': unmod_access_psi_df['original_seq'],\n",
    "    'mutant_seqs': unmod_access_psi_df['mutated_seq'],\n",
    "    'parent_dbs': unmod_access_psi_df['original_dot_bracket'],\n",
    "    'mutant_dbs': unmod_access_psi_df['dot_bracket_mut'],\n",
    "    'goal_types': unmod_access_psi_df['strategy'],\n",
    "    'target_regions_1': unmod_access_psi_df['target_pos_range']\n",
    "}\n",
    "\n",
    "print(\"DataFrame loaded successfully.\")\n",
    "\n",
    "results_df = run_analysis_engine(**column_mapping)\n",
    "\n",
    "dfs_by_logic = {}\n",
    "\n",
    "for name, group in results_df.groupby('Logic_Type_Applied'):\n",
    "    print(f\"Creating DataFrame for logic type: '{name}' with {len(group)} rows.\")\n",
    "    dfs_by_logic[name] = group\n",
    "\n",
    "break_pair_df = dfs_by_logic.get('break_pair')\n",
    "make_pair_df = dfs_by_logic.get('make_pair')\n",
    "\n",
    "print(f\"Number of break pair: {len(break_pair_df)}\")\n",
    "print(f\"Number of make pair: {len(make_pair_df)}\")\n",
    "\n",
    "break_pair_ted_threshold = break_pair_df['TreeEditDistance'].quantile(0.03)\n",
    "make_pair_ted_threshold = make_pair_df['TreeEditDistance'].quantile(0.1)\n",
    "\n",
    "break_pair_off_threshold = break_pair_df['TreeEditDistance'].quantile(0.03)\n",
    "make_pair_off_threshold = make_pair_df['TreeEditDistance'].quantile(0.1)\n",
    "\n",
    "good_break_pair_df = break_pair_df.loc[(break_pair_df['OnTargetScore'] == 3)\n",
    "                                       & (break_pair_df['TreeEditDistance'] <= break_pair_ted_threshold) \n",
    "                                       & (break_pair_df['OffTargetScore'] <= break_pair_off_threshold)\n",
    "                                       ]\n",
    "good_make_pair_df = make_pair_df.loc[(make_pair_df['OnTargetScore'] == 3)\n",
    "                                     & (make_pair_df['TreeEditDistance'] <= make_pair_ted_threshold) \n",
    "                                     & (make_pair_df['OffTargetScore'] <= make_pair_off_threshold)\n",
    "                                     ]\n",
    "\n",
    "print(f\"Number of good break pair: {len(good_break_pair_df)}\")\n",
    "\n",
    "good_break_pair_df.to_csv(\"unmod_good_breakpair_unpaired2.csv\", index=False)\n",
    "print(f\"\\nAnalysis complete. Results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7138fca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded successfully.\n",
      "Starting analysis of 604 entries...\n",
      "Analysis function finished.\n",
      "Creating DataFrame for logic type: 'break_pair' with 419 rows.\n",
      "Creating DataFrame for logic type: 'make_pair' with 185 rows.\n",
      "Number of break pair: 196\n",
      "Number of make pair: 84\n",
      "Number of good break pair: 33\n",
      "Number of good make pair: 17\n",
      "\n",
      "Analysis complete. Results saved.\n"
     ]
    }
   ],
   "source": [
    "pool_access=\"C:/Users/rmrex/OneDrive - Stanford/Martinez Lab/R/Pool2_Mutagenesis/Abridged/unpaired2_pairing/pairing_status_flip_analysis_pool1.csv\"\n",
    "\n",
    "pool_access_df = pd.read_csv(pool_access)\n",
    "\n",
    "column_mapping = {\n",
    "    'mutant_ids': pool_access_df['name'],\n",
    "    'parent_seqs': pool_access_df['original_seq'],\n",
    "    'mutant_seqs': pool_access_df['mutated_seq'],\n",
    "    'parent_dbs': pool_access_df['original_dot_bracket'],\n",
    "    'mutant_dbs': pool_access_df['dot_bracket_mut'],\n",
    "    'goal_types': pool_access_df['strategy'],\n",
    "    'target_regions_1': pool_access_df['target_pos_range']\n",
    "}\n",
    "\n",
    "print(\"DataFrame loaded successfully.\")\n",
    "\n",
    "results_df = run_analysis_engine(**column_mapping)\n",
    "\n",
    "dfs_by_logic = {}\n",
    "\n",
    "for name, group in results_df.groupby('Logic_Type_Applied'):\n",
    "    print(f\"Creating DataFrame for logic type: '{name}' with {len(group)} rows.\")\n",
    "    dfs_by_logic[name] = group\n",
    "\n",
    "pool_break_pair_df = dfs_by_logic.get('break_pair')\n",
    "pool_make_pair_df = dfs_by_logic.get('make_pair')\n",
    "\n",
    "# The concise, single-line solution\n",
    "poolPUS7_make_pair_df = pool_make_pair_df[pool_make_pair_df['mutant_id'].isin(PUS7_union_df['chr'])]\n",
    "poolPUS7_break_pair_df = pool_break_pair_df[pool_break_pair_df['mutant_id'].isin(unuar_df['chr'])]\n",
    "\n",
    "print(f\"Number of break pair: {len(poolPUS7_break_pair_df)}\")\n",
    "print(f\"Number of make pair: {len(poolPUS7_make_pair_df)}\")\n",
    "\n",
    "pool_break_pair_ted_threshold = poolPUS7_break_pair_df['TreeEditDistance'].quantile(0.5)\n",
    "pool_make_pair_ted_threshold = poolPUS7_make_pair_df['TreeEditDistance'].quantile(0.5)\n",
    "\n",
    "pool_break_pair_off_threshold = poolPUS7_break_pair_df['OffTargetScore'].quantile(0.5)\n",
    "pool_make_pair_off_threshold = poolPUS7_make_pair_df['OffTargetScore'].quantile(0.5)\n",
    "\n",
    "pool_good_break_pair_df = poolPUS7_break_pair_df.loc[(poolPUS7_break_pair_df['OnTargetScore'] == 3)\n",
    "                                        & (poolPUS7_break_pair_df['TreeEditDistance'] <= pool_break_pair_ted_threshold) \n",
    "                                        & (poolPUS7_break_pair_df['OffTargetScore'] <= pool_break_pair_off_threshold)\n",
    "                                        ]\n",
    "pool_good_make_pair_df = poolPUS7_make_pair_df.loc[(poolPUS7_make_pair_df['OnTargetScore'] == 3)\n",
    "                                        &  (poolPUS7_make_pair_df['TreeEditDistance'] <= pool_make_pair_ted_threshold) \n",
    "                                        & (poolPUS7_make_pair_df['OffTargetScore'] <= pool_make_pair_off_threshold)\n",
    "                                        ]\n",
    "\n",
    "print(f\"Number of good break pair: {len(pool_good_break_pair_df)}\")\n",
    "print(f\"Number of good make pair: {len(pool_good_make_pair_df)}\")\n",
    "\n",
    "pool_good_break_pair_df.to_csv(\"pool_good_breakpair_unpaired2.csv\", index=False)\n",
    "pool_good_make_pair_df.to_csv(\"pool_good_makepair_unpaired2.csv\", index=False)\n",
    "print(f\"\\nAnalysis complete. Results saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55897bae",
   "metadata": {},
   "source": [
    "## Structure Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc646b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mutations in PUS7 union: 1516\n",
      "Number of mutations in filtered PUS7 union: 1343\n",
      "DataFrame loaded successfully.\n",
      "Starting analysis of 1343 entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmrex\\AppData\\Local\\Temp\\ipykernel_20396\\1465844968.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  poolPUS7_structure_df['goal_type_cat'] = pd.Categorical(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis function finished.\n",
      "Creating DataFrame for logic type: 'downstream_compensation' with 239 rows.\n",
      "Creating DataFrame for logic type: 'downstream_disruption' with 260 rows.\n",
      "Creating DataFrame for logic type: 'total_compensation' with 184 rows.\n",
      "Creating DataFrame for logic type: 'total_disruption' with 225 rows.\n",
      "Creating DataFrame for logic type: 'upstream_compensation' with 222 rows.\n",
      "Creating DataFrame for logic type: 'upstream_disruption' with 213 rows.\n",
      "\n",
      "Number of good downstream disruptions: 47\n",
      "Number of good upstream disruptions: 29\n",
      "Number of good total disruptions: 34\n",
      "\n",
      "Number of downstream compensations: 42\n",
      "Number of upstream compensations: 29\n",
      "Number of total compensations: 26\n",
      "\n",
      "Number of good downstream compensations: 11\n",
      "Number of good upstream compensations: 12\n",
      "Number of good total compensations: 9\n",
      "\n",
      "Analysis complete. Results saved.\n"
     ]
    }
   ],
   "source": [
    "pool_structure=\"C:/Users/rmrex/OneDrive - Stanford/Martinez Lab/R/Pool2_Mutagenesis/Abridged/structure_mutation/all_mutagenesis_results.csv\"\n",
    "\n",
    "pool_structure_df = pd.read_csv(pool_structure)\n",
    "\n",
    "#display(pool_structure_df.head())\n",
    "\n",
    "# filter for PUS7 Union\n",
    "pool_structure_df['name'] = pool_structure_df['original_filename'].str.removesuffix('.fold')\n",
    "poolPUS7_structure_df = pool_structure_df[pool_structure_df['name'].isin(PUS7_union_df['chr'])]\n",
    "\n",
    "print(f\"Number of mutations in PUS7 union: {len(poolPUS7_structure_df)}\")\n",
    "\n",
    "# Remove duplicated total seqeunces that match an up or downstream mutant\n",
    "priority_order = [\n",
    "    'upstream_disrution',\n",
    "    'downstream_disruption',\n",
    "    'total_disruption',\n",
    "    'upstream_compensation',\n",
    "    'downstream_compensation',\n",
    "    'total_compensation'\n",
    "]\n",
    "\n",
    "poolPUS7_structure_df['goal_type_cat'] = pd.Categorical(\n",
    "    poolPUS7_structure_df['goal_type'],\n",
    "    categories=priority_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "filtered_poolPUS7_structure_df = poolPUS7_structure_df.sort_values('goal_type_cat').drop_duplicates(\n",
    "    subset='mutant_seq', \n",
    "    keep='first'\n",
    ")\n",
    "\n",
    "print(f\"Number of mutations in filtered PUS7 union: {len(filtered_poolPUS7_structure_df)}\")\n",
    "\n",
    "\n",
    "column_mapping = {\n",
    "    'mutant_ids': filtered_poolPUS7_structure_df['mutant_id'],\n",
    "    'parent_seqs': filtered_poolPUS7_structure_df['parent_seq'],\n",
    "    'mutant_seqs': filtered_poolPUS7_structure_df['mutant_seq'],\n",
    "    'parent_dbs': filtered_poolPUS7_structure_df['parent_db'],\n",
    "    'mutant_dbs': filtered_poolPUS7_structure_df['mutant_db'],\n",
    "    'goal_types': filtered_poolPUS7_structure_df['goal_type'],\n",
    "    'target_regions_1': filtered_poolPUS7_structure_df['target_mut_region']\n",
    "}\n",
    "\n",
    "print(\"DataFrame loaded successfully.\")\n",
    "\n",
    "results_df = run_analysis_engine(**column_mapping)\n",
    "\n",
    "dfs_by_logic = {}\n",
    "\n",
    "for name, group in results_df.groupby('goal_type'):\n",
    "    print(f\"Creating DataFrame for logic type: '{name}' with {len(group)} rows.\")\n",
    "    dfs_by_logic[name] = group\n",
    "\n",
    "down_disr_df = dfs_by_logic.get('downstream_disruption')\n",
    "down_comp_df = dfs_by_logic.get('downstream_compensation')\n",
    "up_disr_df = dfs_by_logic.get('upstream_disruption')\n",
    "up_comp_df = dfs_by_logic.get('upstream_compensation')\n",
    "total_disr_df = dfs_by_logic.get('total_disruption')\n",
    "total_comp_df = dfs_by_logic.get('total_compensation')\n",
    "\n",
    "down_disrupt_on_threshold = down_disr_df['OnTargetScore'].quantile(0.5)\n",
    "down_disrupt_ted_threshold = down_disr_df['TreeEditDistance'].quantile(0.5)\n",
    "down_disrupt_off_threshold = down_disr_df['OffTargetScore'].quantile(0.3)\n",
    "\n",
    "up_disrupt_on_threshold = up_disr_df['OnTargetScore'].quantile(0.5)\n",
    "up_disrupt_ted_threshold = up_disr_df['TreeEditDistance'].quantile(0.5)\n",
    "up_disrupt_off_threshold = up_disr_df['OffTargetScore'].quantile(0.3)\n",
    "\n",
    "tot_disrupt_on_threshold = total_disr_df['OnTargetScore'].quantile(0.5)\n",
    "tot_disrupt_ted_threshold = total_disr_df['TreeEditDistance'].quantile(0.5)\n",
    "tot_disrupt_off_threshold = total_disr_df['OffTargetScore'].quantile(0.3)\n",
    "\n",
    "\n",
    "good_down_disr_df = down_disr_df.loc[(down_disr_df['OnTargetScore'] <= down_disrupt_on_threshold)\n",
    "                                        & (down_disr_df['TreeEditDistance'] <= down_disrupt_ted_threshold) \n",
    "                                        & (down_disr_df['OffTargetScore'] <= down_disrupt_off_threshold)\n",
    "                                        ]\n",
    "good_up_disr_df = up_disr_df.loc[(up_disr_df['OnTargetScore'] <= up_disrupt_on_threshold)\n",
    "                                        & (up_disr_df['TreeEditDistance'] <= up_disrupt_ted_threshold) \n",
    "                                        & (up_disr_df['OffTargetScore'] <= up_disrupt_off_threshold)\n",
    "                                        ]\n",
    "good_tot_disr_df = total_disr_df.loc[(total_disr_df['OnTargetScore'] <= tot_disrupt_on_threshold)\n",
    "                                        & (total_disr_df['TreeEditDistance'] <= tot_disrupt_ted_threshold) \n",
    "                                        & (total_disr_df['OffTargetScore'] <= tot_disrupt_off_threshold)\n",
    "                                        ]\n",
    "print()\n",
    "print(f\"Number of good downstream disruptions: {len(good_down_disr_df)}\")\n",
    "print(f\"Number of good upstream disruptions: {len(good_up_disr_df)}\")\n",
    "print(f\"Number of good total disruptions: {len(good_tot_disr_df)}\")\n",
    "\n",
    "successful_down_disr = set(\n",
    "    good_down_disr_df['mutant_id'].str.replace(r'_disruption$|_compensation$', '', regex=True)\n",
    ")\n",
    "final_down_comp_df = down_comp_df[\n",
    "    down_comp_df['mutant_id'].str.replace(r'_disruption$|_compensation$', '', regex=True).isin(successful_down_disr)\n",
    "].copy()\n",
    "\n",
    "\n",
    "successful_up_disr = set(\n",
    "    good_up_disr_df['mutant_id'].str.replace(r'_disruption$|_compensation$', '', regex=True)\n",
    ")\n",
    "final_up_comp_df = up_comp_df[\n",
    "    up_comp_df['mutant_id'].str.replace(r'_disruption$|_compensation$', '', regex=True).isin(successful_up_disr)\n",
    "].copy()\n",
    "\n",
    "\n",
    "successful_tot_disr = set(\n",
    "    good_tot_disr_df['mutant_id'].str.replace(r'_disruption$|_compensation$', '', regex=True)\n",
    ")\n",
    "final_tot_comp_df = total_comp_df[\n",
    "    total_comp_df['mutant_id'].str.replace(r'_disruption$|_compensation$', '', regex=True).isin(successful_tot_disr)\n",
    "].copy()\n",
    "\n",
    "print()\n",
    "print(f\"Number of downstream compensations: {len(final_down_comp_df)}\")\n",
    "print(f\"Number of upstream compensations: {len(final_up_comp_df)}\")\n",
    "print(f\"Number of total compensations: {len(final_tot_comp_df)}\")\n",
    "\n",
    "down_comp_on_threshold = final_down_comp_df['OnTargetScore'].quantile(0.5)\n",
    "down_comp_ted_threshold = final_down_comp_df['TreeEditDistance'].quantile(0.5)\n",
    "down_comp_off_threshold = final_down_comp_df['OffTargetScore'].quantile(0.5)\n",
    "\n",
    "up_comp_on_threshold = final_up_comp_df['OnTargetScore'].quantile(0.5)\n",
    "up_comp_ted_threshold = final_up_comp_df['TreeEditDistance'].quantile(0.5)\n",
    "up_comp_off_threshold = final_up_comp_df['OffTargetScore'].quantile(0.5)\n",
    "\n",
    "tot_comp_on_threshold = final_tot_comp_df['OnTargetScore'].quantile(0.5)\n",
    "tot_comp_ted_threshold = final_tot_comp_df['TreeEditDistance'].quantile(0.5)\n",
    "tot_comp_off_threshold = final_tot_comp_df['OffTargetScore'].quantile(0.5)\n",
    "\n",
    "\n",
    "good_down_comp_df = final_down_comp_df.loc[(final_down_comp_df['OnTargetScore'] <= down_comp_on_threshold)\n",
    "                                        & (final_down_comp_df['TreeEditDistance'] <= down_comp_ted_threshold) \n",
    "                                        & (final_down_comp_df['OffTargetScore'] <= down_comp_off_threshold)\n",
    "                                        ]\n",
    "good_up_comp_df = final_up_comp_df.loc[(final_up_comp_df['OnTargetScore'] <= up_comp_on_threshold)\n",
    "                                        & (final_up_comp_df['TreeEditDistance'] <= up_comp_ted_threshold) \n",
    "                                        & (final_up_comp_df['OffTargetScore'] <= up_comp_off_threshold)\n",
    "                                        ]\n",
    "good_tot_comp_df = final_tot_comp_df.loc[(final_tot_comp_df['OnTargetScore'] <= tot_comp_on_threshold)\n",
    "                                        & (final_tot_comp_df['TreeEditDistance'] <= tot_comp_ted_threshold) \n",
    "                                        & (final_tot_comp_df['OffTargetScore'] <= tot_comp_off_threshold)\n",
    "                                        ]\n",
    "print()\n",
    "print(f\"Number of good downstream compensations: {len(good_down_comp_df)}\")\n",
    "print(f\"Number of good upstream compensations: {len(good_up_comp_df)}\")\n",
    "print(f\"Number of good total compensations: {len(good_tot_comp_df)}\")\n",
    "\n",
    "# Specific sites to include\n",
    "sites = [\"RHBDD2\", \"IGF2BP1\", \"FIS1\", \"HDAC6\", \"EIF5\"]\n",
    "specsite_structure_df = results_df[results_df['mutant_id'].str.contains('|'.join(sites), case=False, na=False)]\n",
    "#specsite_structure_df = specsite_structure_df.query(\"goal_type != 'total_compensation'\")\n",
    "\n",
    "specsite_structure_df.to_csv(\"pool_specific_struct_mut.csv\", index=False)\n",
    "good_down_disr_df.to_csv(\"pool_good_down_disruption.csv\", index=False)\n",
    "good_up_disr_df.to_csv(\"pool_good_up_disruption.csv\", index=False)\n",
    "good_tot_disr_df.to_csv(\"pool_good_tot_disruption.csv\", index=False)\n",
    "good_down_comp_df.to_csv(\"pool_good_down_compensation.csv\", index=False)\n",
    "good_up_comp_df.to_csv(\"pool_good_up_compensation.csv\", index=False)\n",
    "good_tot_comp_df.to_csv(\"pool_good_tot_compensation.csv\", index=False)\n",
    "print(f\"\\nAnalysis complete. Results saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f290c0",
   "metadata": {},
   "source": [
    "## Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "768c397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mutations in PUS7 union: 1290\n",
      "Number of mutations in filtered PUS7 union: 1061\n",
      "DataFrame loaded successfully.\n",
      "Starting analysis of 1061 entries...\n",
      "Analysis function finished.\n",
      "Creating DataFrame for logic type: 'downstream_destabilizing' with 237 rows.\n",
      "Creating DataFrame for logic type: 'downstream_stabilizing' with 172 rows.\n",
      "Creating DataFrame for logic type: 'total_destabilizing' with 162 rows.\n",
      "Creating DataFrame for logic type: 'total_stabilizing' with 97 rows.\n",
      "Creating DataFrame for logic type: 'upstream_destabilizing' with 214 rows.\n",
      "Creating DataFrame for logic type: 'upstream_stabilizing' with 179 rows.\n",
      "--- DataFrame Lengths ---\n",
      "down_stab_df: 172 rows\n",
      "Number of good stability mutations in down_stab_df: 31\n",
      "down_destab_df: 237 rows\n",
      "Number of good stability mutations in down_destab_df: 40\n",
      "up_stab_df: 179 rows\n",
      "Number of good stability mutations in up_stab_df: 34\n",
      "up_destab_df: 214 rows\n",
      "Number of good stability mutations in up_destab_df: 34\n",
      "total_stab_df: 97 rows\n",
      "Number of good stability mutations in total_stab_df: 16\n",
      "total_destab_df: 162 rows\n",
      "Number of good stability mutations in total_destab_df: 29\n",
      "\n",
      "Analysis complete. Results saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmrex\\AppData\\Local\\Temp\\ipykernel_20396\\2600160809.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  poolPUS7_stability_df['target_region'] = np.select(conditions, choices, default=None)\n",
      "C:\\Users\\rmrex\\AppData\\Local\\Temp\\ipykernel_20396\\2600160809.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  poolPUS7_stability_df['goal_type_cat'] = pd.Categorical(\n"
     ]
    }
   ],
   "source": [
    "pool_stability=\"C:/Users/rmrex/OneDrive - Stanford/Martinez Lab/R/Pool2_Mutagenesis/Abridged/MFE_alterations/significant_mfe_mutants_pool1.csv\"\n",
    "\n",
    "pool_stability_df = pd.read_csv(pool_stability)\n",
    "\n",
    "# filter for PUS7 Union\n",
    "pool_stability_df['name'] = pool_stability_df['original_filename'].str.removesuffix('.fold')\n",
    "poolPUS7_stability_df = pool_stability_df[pool_stability_df['name'].isin(PUS7_union_df['chr'])]\n",
    "\n",
    "\n",
    "# Add in target ranges\n",
    "# upstream = 56-63\n",
    "# downstram = 69-81\n",
    "# total = 56-63, 69-81\n",
    "conditions = [\n",
    "    poolPUS7_stability_df['type'].str.contains('total', na=False),\n",
    "    poolPUS7_stability_df['type'].str.contains('downstream', na=False),\n",
    "    poolPUS7_stability_df['type'].str.contains('upstream', na=False)\n",
    "]\n",
    "# must match order of conditions list\n",
    "choices = [\n",
    "    '56-63, 69-81',\n",
    "    '69-81',\n",
    "    '56-63'\n",
    "]\n",
    "poolPUS7_stability_df['target_region'] = np.select(conditions, choices, default=None)\n",
    "\n",
    "print(f\"Number of mutations in PUS7 union: {len(poolPUS7_stability_df)}\")\n",
    "\n",
    "# Remove duplicated total seqeunces that match an up or downstream mutant\n",
    "# redundant_sequences = set(\n",
    "#     poolPUS7_stability_df.loc[\n",
    "#         poolPUS7_stability_df['type'].str.contains('up|down', na=False), 'mutant_seq'\n",
    "#     ]\n",
    "# )\n",
    "# mask_to_keep = ~(\n",
    "#     poolPUS7_stability_df['type'].str.contains('total', na=False) &\n",
    "#     poolPUS7_stability_df['mutant_seq'].isin(redundant_sequences)\n",
    "# )\n",
    "\n",
    "# filtered_poolPUS7_stability_df = poolPUS7_stability_df[mask_to_keep].copy()\n",
    "\n",
    "priority_order = [\n",
    "    'upstream_stabilizing',\n",
    "    'downstream_stabilizing',\n",
    "    'total_stabilizing',\n",
    "    'upstream_destabilizing',\n",
    "    'downstream_destabilizing',\n",
    "    'total_destabilizing'\n",
    "]\n",
    "\n",
    "poolPUS7_stability_df['goal_type_cat'] = pd.Categorical(\n",
    "    poolPUS7_stability_df['type'],\n",
    "    categories=priority_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "filtered_poolPUS7_stability_df = poolPUS7_stability_df.sort_values('goal_type_cat').drop_duplicates(\n",
    "    subset='mutant_seq', \n",
    "    keep='first'\n",
    ")\n",
    "\n",
    "print(f\"Number of mutations in filtered PUS7 union: {len(filtered_poolPUS7_stability_df)}\")\n",
    "#display(poolPUS7_stability_df.head())\n",
    "\n",
    "\n",
    "column_mapping = {\n",
    "    'mutant_ids': filtered_poolPUS7_stability_df['name'],\n",
    "    'parent_seqs': filtered_poolPUS7_stability_df['sequence'],\n",
    "    'mutant_seqs': filtered_poolPUS7_stability_df['mutant_seq'],\n",
    "    'parent_dbs': filtered_poolPUS7_stability_df['original_db'],\n",
    "    'mutant_dbs': filtered_poolPUS7_stability_df['mutant_db'],\n",
    "    'goal_types': filtered_poolPUS7_stability_df['type'],\n",
    "    'target_regions_1': filtered_poolPUS7_stability_df['target_region']\n",
    "}\n",
    "\n",
    "print(\"DataFrame loaded successfully.\")\n",
    "\n",
    "results_df = run_analysis_engine(**column_mapping)\n",
    "\n",
    "dfs_by_logic = {}\n",
    "\n",
    "for name, group in results_df.groupby('goal_type'):\n",
    "    print(f\"Creating DataFrame for logic type: '{name}' with {len(group)} rows.\")\n",
    "    dfs_by_logic[name] = group\n",
    "\n",
    "down_stab_df = dfs_by_logic.get('downstream_stabilizing')\n",
    "down_destab_df = dfs_by_logic.get('downstream_destabilizing')\n",
    "up_stab_df = dfs_by_logic.get('upstream_stabilizing')\n",
    "up_destab_df = dfs_by_logic.get('upstream_destabilizing')\n",
    "total_stab_df = dfs_by_logic.get('total_stabilizing')\n",
    "total_destab_df = dfs_by_logic.get('total_destabilizing')\n",
    "\n",
    "dataframes_to_check = {\n",
    "    \"down_stab_df\": down_stab_df,\n",
    "    \"down_destab_df\": down_destab_df,\n",
    "    \"up_stab_df\": up_stab_df,\n",
    "    \"up_destab_df\": up_destab_df,\n",
    "    \"total_stab_df\": total_stab_df,\n",
    "    \"total_destab_df\": total_destab_df\n",
    "}\n",
    "\n",
    "print(\"--- DataFrame Lengths ---\")\n",
    "for name, df in dataframes_to_check.items():\n",
    "    if df is not None:\n",
    "        #print()\n",
    "        print(f\"{name}: {len(df)} rows\")\n",
    "\n",
    "        ted_threshold = df['TreeEditDistance'].quantile(0.25)\n",
    "        off_threshold = df['OffTargetScore'].quantile(0.25)\n",
    "\n",
    "        good_df = df.loc[(df['TreeEditDistance'] <= ted_threshold) \n",
    "                                & (df['OffTargetScore'] <= off_threshold)\n",
    "                                ]\n",
    "        print(f\"Number of good stability mutations in {name}: {len(good_df)}\")\n",
    "\n",
    "        output_filename = f\"pool_good_{name}.csv\"\n",
    "        good_df.to_csv(output_filename, index=False)\n",
    "\n",
    "    else:\n",
    "        print(f\"{name}: Does not exist (None)\")\n",
    "\n",
    "print(f\"\\nAnalysis complete. Results saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rna_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
